{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fdd7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip #for model classification\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm#lib to show progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba83e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe54866",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "db_url=os.getenv(\"DB_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbb5de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(db_url)\n",
    "db= client[\"Toyota_cars\"]\n",
    "collection = db[\"listings\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47850c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_clip_function():\n",
    "    LABELS = [\n",
    "    \"a clear photo of a car exterior (outside view of car)\",\n",
    "    \"a clear photo of a car interior (seats, dashboard, cabin)\",\n",
    "    \"a clear photo of a car engine bay\",\n",
    "    \"a photo of car key or keychain\",\n",
    "    \"a random, unclear, blurry, unrelated or unidentified photo\"\n",
    "]\n",
    "\n",
    "    CATEGORY_FIELDS = {\n",
    "    0: \"exterior_images\",\n",
    "    1: \"interior_images\",\n",
    "    2: \"engine_images\",\n",
    "    3: \"key_images\",\n",
    "    4: \"unidentified_images\"\n",
    "}\n",
    "\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    text_tokens = clip.tokenize(LABELS).to(device)\n",
    "    session=requests.Session()\n",
    "    \n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.pakwheels.com/used-cars/honda/32\"\n",
    "}\n",
    "\n",
    "    return LABELS,CATEGORY_FIELDS,device,model,preprocess,text_tokens,session,headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3232bbcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'clip' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m LABELS,CATEGORY_FIELDS,device,model,preprocess,text_tokens,session,headers\u001b[38;5;241m=\u001b[39m\u001b[43mset_clip_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 20\u001b[0m, in \u001b[0;36mset_clip_function\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     CATEGORY_FIELDS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexterior_images\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterior_images\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munidentified_images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     19\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m     model, preprocess \u001b[38;5;241m=\u001b[39m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViT-B/32\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     21\u001b[0m     text_tokens \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mtokenize(LABELS)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     22\u001b[0m     session\u001b[38;5;241m=\u001b[39mrequests\u001b[38;5;241m.\u001b[39mSession()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'clip' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "LABELS,CATEGORY_FIELDS,device,model,preprocess,text_tokens,session,headers=set_clip_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae6f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_url(\n",
    "    url,\n",
    "    model,\n",
    "    preprocess,\n",
    "    text_tokens,\n",
    "    labels,\n",
    "    device,\n",
    "    headers,\n",
    "    session,\n",
    "    confidence_threshold=0.5\n",
    "):\n",
    "    try:\n",
    "        response = session.get(url,headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        image_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image_tensor)\n",
    "            text_features = model.encode_text(text_tokens)\n",
    "            similarity = (image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "        best_idx = similarity.argmax().item()\n",
    "        confidence = similarity[0][best_idx].item()\n",
    "        label = labels[best_idx]\n",
    "\n",
    "        if confidence < confidence_threshold:\n",
    "            return None, confidence\n",
    "\n",
    "        return label, confidence\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed on {url}: {e}\")\n",
    "        return None, 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e07928c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(\n",
    "    collection,\n",
    "    model,\n",
    "    preprocess,\n",
    "    text_tokens,\n",
    "    labels,\n",
    "    device,\n",
    "    headers,\n",
    "    session,\n",
    "):\n",
    "    print(\"Fetching document IDs...\")\n",
    "    \n",
    "    all_ids = [\n",
    "        doc[\"_id\"] \n",
    "        for doc in collection.find(\n",
    "            {\"images\": {\"$exists\": True}}, \n",
    "            {\"_id\": 1}\n",
    "        )\n",
    "    ]\n",
    "    print(f\"Found {len(all_ids)} documents to process\")\n",
    "    for doc_id in tqdm(all_ids, desc=\"Processing documents\"):\n",
    "        doc = collection.find_one({\"_id\": doc_id})\n",
    "        if not doc:\n",
    "            continue\n",
    "\n",
    "        # Create empty buckets for all categories\n",
    "        categorized = {field: [] for field in CATEGORY_FIELDS.values()}\n",
    "\n",
    "        for url in doc.get(\"images\", []):\n",
    "            label, conf = classify_image_url(\n",
    "                url=url,\n",
    "                model=model,\n",
    "                preprocess=preprocess,\n",
    "                text_tokens=text_tokens,\n",
    "                labels=labels,\n",
    "                device=device,\n",
    "                headers=headers,\n",
    "                session=session\n",
    "            )\n",
    "\n",
    "            if label is None:\n",
    "                continue\n",
    "\n",
    "            # Find index of predicted label\n",
    "            idx = labels.index(label)\n",
    "\n",
    "            # Get correct Mongo field\n",
    "            mongo_field = CATEGORY_FIELDS[idx]\n",
    "\n",
    "            categorized[mongo_field].append(url)\n",
    "\n",
    "        # Save everything in the same document\n",
    "        collection.update_one(\n",
    "            {\"_id\": doc_id},\n",
    "            {\"$set\": categorized}\n",
    "        )\n",
    "\n",
    "    print(\"✅ Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d753a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching document IDs...\n",
      "Found 2613 documents to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  76%|███████▋  | 1997/2613 [5:59:48<1:59:42, 11.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed on https://cache2.pakwheels.com/ad_pictures/1355/honda-city-1-2l-cvt-2024-135598086.webp: HTTPSConnectionPool(host='cache2.pakwheels.com', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 2613/2613 [7:36:20<00:00, 10.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_documents(collection,model,preprocess,text_tokens,LABELS,device,headers,session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b64e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified documents: 7\n"
     ]
    }
   ],
   "source": [
    "# result = collection.update_many(\n",
    "#     {},\n",
    "#     {\n",
    "#         \"$unset\": {\n",
    "#             \"exterior_images\": \"\",\n",
    "#             \"interior_images\": \"\",\n",
    "#             \"engine_images\": \"\",\n",
    "#             \"dashboard_images\": \"\",\n",
    "#             \"seat_images\": \"\",\n",
    "#             \"infotainment_images\": \"\",\n",
    "#             \"doorpanel_images\": \"\",\n",
    "#             \"trunk_images\": \"\",\n",
    "#             \"tire_images\": \"\",\n",
    "#             \"key_images\": \"\",\n",
    "#             \"document_images\": \"\",\n",
    "#             \"damage_images\": \"\",\n",
    "#             \"blurry_images\": \"\",\n",
    "#             \"junk_images\": \"\"\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# print(\"Modified documents:\", result.modified_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab81cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
